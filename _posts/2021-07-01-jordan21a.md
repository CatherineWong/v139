---
title: Provable Lipschitz Certification for Generative Models
abstract: We present a scalable technique for upper bounding the Lipschitz constant
  of generative models. We relate this quantity to the maximal norm over the set of
  attainable vector-Jacobian products of a given generative model. We approximate
  this set by layerwise convex approximations using zonotopes. Our approach generalizes
  and improves upon prior work using zonotope transformers and we extend to Lipschitz
  estimation of neural networks with large output dimension. This provides efficient
  and tight bounds on small networks and can scale to generative models on VAE and
  DCGAN architectures.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jordan21a
month: 0
tex_title: Provable Lipschitz Certification for Generative Models
firstpage: 5118
lastpage: 5126
page: 5118-5126
order: 5118
cycles: false
bibtex_author: Jordan, Matt and Dimakis, Alex
author:
- given: Matt
  family: Jordan
- given: Alex
  family: Dimakis
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/jordan21a/jordan21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/jordan21a/jordan21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
