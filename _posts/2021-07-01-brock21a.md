---
title: High-Performance Large-Scale Image Recognition Without Normalization
abstract: Batch normalization is a key component of most image classification models,
  but it has many undesirable properties stemming from its dependence on the batch
  size and interactions between examples. Although recent work has succeeded in training
  deep ResNets without normalization layers, these models do not match the test accuracies
  of the best batch-normalized networks, and are often unstable for large learning
  rates or strong data augmentations. In this work, we develop an adaptive gradient
  clipping technique which overcomes these instabilities, and design a significantly
  improved class of Normalizer-Free ResNets. Our smaller models match the test accuracy
  of an EfficientNet-B7 on ImageNet while being up to 8.7x faster to train, and our
  largest models attain a new state-of-the-art top-1 accuracy of 86.5%. In addition,
  Normalizer-Free models attain significantly better performance than their batch-normalized
  counterparts when fine-tuning on ImageNet after large-scale pre-training on a dataset
  of 300 million labeled images, with our best models obtaining an accuracy of 89.2%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: brock21a
month: 0
tex_title: High-Performance Large-Scale Image Recognition Without Normalization
firstpage: 1059
lastpage: 1071
page: 1059-1071
order: 1059
cycles: false
bibtex_author: Brock, Andy and De, Soham and Smith, Samuel L and Simonyan, Karen
author:
- given: Andy
  family: Brock
- given: Soham
  family: De
- given: Samuel L
  family: Smith
- given: Karen
  family: Simonyan
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/brock21a/brock21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
