---
title: Learning Noise Transition Matrix from Only Noisy Labels via Total Variation
  Regularization
abstract: Many weakly supervised classification methods employ a noise transition
  matrix to capture the class-conditional label corruption. To estimate the transition
  matrix from noisy data, existing methods often need to estimate the noisy class-posterior,
  which could be unreliable due to the overconfidence of neural networks. In this
  work, we propose a theoretically grounded method that can estimate the noise transition
  matrix and learn a classifier simultaneously, without relying on the error-prone
  noisy class-posterior estimation. Concretely, inspired by the characteristics of
  the stochastic label corruption process, we propose total variation regularization,
  which encourages the predicted probabilities to be more distinguishable from each
  other. Under mild assumptions, the proposed method yields a consistent estimator
  of the transition matrix. We show the effectiveness of the proposed method through
  experiments on benchmark and real-world datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang21n
month: 0
tex_title: Learning Noise Transition Matrix from Only Noisy Labels via Total Variation
  Regularization
firstpage: 12501
lastpage: 12512
page: 12501-12512
order: 12501
cycles: false
bibtex_author: Zhang, Yivan and Niu, Gang and Sugiyama, Masashi
author:
- given: Yivan
  family: Zhang
- given: Gang
  family: Niu
- given: Masashi
  family: Sugiyama
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/zhang21n/zhang21n.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/zhang21n/zhang21n-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
