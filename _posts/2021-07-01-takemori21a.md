---
title: Approximation Theory Based Methods for RKHS Bandits
abstract: The RKHS bandit problem (also called kernelized multi-armed bandit problem)
  is an online optimization problem of non-linear functions with noisy feedback. Although
  the problem has been extensively studied, there are unsatisfactory results for some
  problems compared to the well-studied linear bandit case. Specifically, there is
  no general algorithm for the adversarial RKHS bandit problem. In addition, high
  computational complexity of existing algorithms hinders practical application. We
  address these issues by considering a novel amalgamation of approximation theory
  and the misspecified linear bandit problem. Using an approximation method, we propose
  efficient algorithms for the stochastic RKHS bandit problem and the first general
  algorithm for the adversarial RKHS bandit problem. Furthermore, we empirically show
  that one of our proposed methods has comparable cumulative regret to IGP-UCB and
  its running time is much shorter.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: takemori21a
month: 0
tex_title: Approximation Theory Based Methods for RKHS Bandits
firstpage: 10076
lastpage: 10085
page: 10076-10085
order: 10076
cycles: false
bibtex_author: Takemori, Sho and Sato, Masahiro
author:
- given: Sho
  family: Takemori
- given: Masahiro
  family: Sato
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/takemori21a/takemori21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/takemori21a/takemori21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
