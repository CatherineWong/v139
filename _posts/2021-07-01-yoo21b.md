---
title: Conditional Temporal Neural Processes with Covariance Loss
abstract: We introduce a novel loss function, Covariance Loss, which is conceptually
  equivalent to conditional neural processes and has a form of regularization so that
  is applicable to many kinds of neural networks. With the proposed loss, mappings
  from input variables to target variables are highly affected by dependencies of
  target variables as well as mean activation and mean dependencies of input and target
  variables. This nature enables the resulting neural networks to become more robust
  to noisy observations and recapture missing dependencies from prior information.
  In order to show the validity of the proposed loss, we conduct extensive sets of
  experiments on real-world datasets with state-of-the-art models and discuss the
  benefits and drawbacks of the proposed Covariance Loss.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yoo21b
month: 0
tex_title: Conditional Temporal Neural Processes with Covariance Loss
firstpage: 12051
lastpage: 12061
page: 12051-12061
order: 12051
cycles: false
bibtex_author: Yoo, Boseon and Lee, Jiwoo and Ju, Janghoon and Chung, Seijun and Kim,
  Soyeon and Choi, Jaesik
author:
- given: Boseon
  family: Yoo
- given: Jiwoo
  family: Lee
- given: Janghoon
  family: Ju
- given: Seijun
  family: Chung
- given: Soyeon
  family: Kim
- given: Jaesik
  family: Choi
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/yoo21b/yoo21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/yoo21b/yoo21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
