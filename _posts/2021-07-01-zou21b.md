---
title: On the Convergence of Hamiltonian Monte Carlo with Stochastic Gradients
abstract: 'Hamiltonian Monte Carlo (HMC), built based on the Hamiltonâ€™s equation,
  has been witnessed great success in sampling from high-dimensional posterior distributions.
  However, it also suffers from computational inefficiency, especially for large training
  datasets. One common idea to overcome this computational bottleneck is using stochastic
  gradients, which only queries a mini-batch of training data in each iteration. However,
  unlike the extensive studies on the convergence analysis of HMC using full gradients,
  few works focus on establishing the convergence guarantees of stochastic gradient
  HMC algorithms. In this paper, we propose a general framework for proving the convergence
  rate of HMC with stochastic gradient estimators, for sampling from strongly log-concave
  and log-smooth target distributions. We show that the convergence to the target
  distribution in $2$-Wasserstein distance can be guaranteed as long as the stochastic
  gradient estimator is unbiased and its variance is upper bounded along the algorithm
  trajectory. We further apply the proposed framework to analyze the convergence rates
  of HMC with four standard stochastic gradient estimators: mini-batch stochastic
  gradient (SG), stochastic variance reduced gradient (SVRG), stochastic average gradient
  (SAGA), and control variate gradient (CVG). Theoretical results explain the inefficiency
  of mini-batch SG, and suggest that SVRG and SAGA perform better in the tasks with
  high-precision requirements, while CVG performs better for large dataset. Experiment
  results verify our theoretical findings.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zou21b
month: 0
tex_title: On the Convergence of Hamiltonian Monte Carlo with Stochastic Gradients
firstpage: 13012
lastpage: 13022
page: 13012-13022
order: 13012
cycles: false
bibtex_author: Zou, Difan and Gu, Quanquan
author:
- given: Difan
  family: Zou
- given: Quanquan
  family: Gu
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/zou21b/zou21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/zou21b/zou21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
