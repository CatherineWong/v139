---
title: Learning Transferable Visual Models From Natural Language Supervision
abstract: State-of-the-art computer vision systems are trained to predict a fixed
  set of predetermined object categories. This restricted form of supervision limits
  their generality and usability since additional labeled data is needed to specify
  any other visual concept. Learning directly from raw text about images is a promising
  alternative which leverages a much broader source of supervision. We demonstrate
  that the simple pre-training task of predicting which caption goes with which image
  is an efficient and scalable way to learn SOTA image representations from scratch
  on a dataset of 400 million (image, text) pairs collected from the internet. After
  pre-training, natural language is used to reference learned visual concepts (or
  describe new ones) enabling zero-shot transfer of the model to downstream tasks.
  We study the performance of this approach by benchmarking on over 30 different existing
  computer vision datasets, spanning tasks such as OCR, action recognition in videos,
  geo-localization, and many types of fine-grained object classification. The model
  transfers non-trivially to most tasks and is often competitive with a fully supervised
  baseline without the need for any dataset specific training. For instance, we match
  the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to
  use any of the 1.28 million training examples it was trained on.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: radford21a
month: 0
tex_title: Learning Transferable Visual Models From Natural Language Supervision
firstpage: 8748
lastpage: 8763
page: 8748-8763
order: 8748
cycles: false
bibtex_author: Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya
  and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and
  Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya
author:
- given: Alec
  family: Radford
- given: Jong Wook
  family: Kim
- given: Chris
  family: Hallacy
- given: Aditya
  family: Ramesh
- given: Gabriel
  family: Goh
- given: Sandhini
  family: Agarwal
- given: Girish
  family: Sastry
- given: Amanda
  family: Askell
- given: Pamela
  family: Mishkin
- given: Jack
  family: Clark
- given: Gretchen
  family: Krueger
- given: Ilya
  family: Sutskever
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/radford21a/radford21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/radford21a/radford21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
