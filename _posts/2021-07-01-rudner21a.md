---
title: On Signal-to-Noise Ratio Issues in Variational Inference for Deep Gaussian
  Processes
abstract: We show that the gradient estimates used in training Deep Gaussian Processes
  (DGPs) with importance-weighted variational inference are susceptible to signal-to-noise
  ratio (SNR) issues. Specifically, we show both theoretically and via an extensive
  empirical evaluation that the SNR of the gradient estimates for the latent variableâ€™s
  variational parameters decreases as the number of importance samples increases.
  As a result, these gradient estimates degrade to pure noise if the number of importance
  samples is too large. To address this pathology, we show how doubly-reparameterized
  gradient estimators, originally proposed for training variational autoencoders,
  can be adapted to the DGP setting and that the resultant estimators completely remedy
  the SNR issue, thereby providing more reliable training. Finally, we demonstrate
  that our fix can lead to consistent improvements in the predictive performance of
  DGP models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rudner21a
month: 0
tex_title: On Signal-to-Noise Ratio Issues in Variational Inference for Deep Gaussian
  Processes
firstpage: 9148
lastpage: 9156
page: 9148-9156
order: 9148
cycles: false
bibtex_author: Rudner, Tim G. J. and Key, Oscar and Gal, Yarin and Rainforth, Tom
author:
- given: Tim G. J.
  family: Rudner
- given: Oscar
  family: Key
- given: Yarin
  family: Gal
- given: Tom
  family: Rainforth
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/rudner21a/rudner21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/rudner21a/rudner21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
