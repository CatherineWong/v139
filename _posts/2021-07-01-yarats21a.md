---
title: Reinforcement Learning with Prototypical Representations
abstract: Learning effective representations in image-based environments is crucial
  for sample efficient Reinforcement Learning (RL). Unfortunately, in RL, representation
  learning is confounded with the exploratory experience of the agent â€“ learning a
  useful representation requires diverse data, while effective exploration is only
  possible with coherent representations. Furthermore, we would like to learn representations
  that not only generalize across tasks but also accelerate downstream exploration
  for efficient task-specific training. To address these challenges we propose Proto-RL,
  a self-supervised framework that ties representation learning with exploration through
  prototypical representations. These prototypes simultaneously serve as a summarization
  of the exploratory experience of an agent as well as a basis for representing observations.
  We pre-train these task-agnostic representations and prototypes on environments
  without downstream task information. This enables state-of-the-art downstream policy
  learning on a set of difficult continuous control tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yarats21a
month: 0
tex_title: Reinforcement Learning with Prototypical Representations
firstpage: 11920
lastpage: 11931
page: 11920-11931
order: 11920
cycles: false
bibtex_author: Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel
author:
- given: Denis
  family: Yarats
- given: Rob
  family: Fergus
- given: Alessandro
  family: Lazaric
- given: Lerrel
  family: Pinto
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/yarats21a/yarats21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
