---
title: 'Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be
  Exponentially Harder than Online RL'
abstract: Several practical applications of reinforcement learning involve an agent
  learning from past data without the possibility of further exploration. Often these
  applications require us to 1) identify a near optimal policy or to 2) estimate the
  value of a target policy. For both tasks we derive exponential information-theoretic
  lower bounds in discounted infinite horizon MDPs with a linear function representation
  for the action value function even if 1) realizability holds, 2) the batch algorithm
  observes the exact reward and transition functions, and 3) the batch algorithm is
  given the best a priori data distribution for the problem class. Our work introduces
  a new ‘oracle + batch algorithm’ framework to prove lower bounds that hold for every
  distribution. The work shows an exponential separation between batch and online
  reinforcement learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zanette21a
month: 0
tex_title: 'Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can
  be Exponentially Harder than Online RL'
firstpage: 12287
lastpage: 12297
page: 12287-12297
order: 12287
cycles: false
bibtex_author: Zanette, Andrea
author:
- given: Andrea
  family: Zanette
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/zanette21a/zanette21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/zanette21a/zanette21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
