---
title: 'LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning'
abstract: While designing inductive bias in neural architectures has been widely studied,
  we hypothesize that transformer networks are flexible enough to learn inductive
  bias from suitable generic tasks. Here, we replace architecture engineering by encoding
  inductive bias in the form of datasets. Inspired by Peirceâ€™s view that deduction,
  induction, and abduction are the primitives of reasoning, we design three synthetic
  tasks that are intended to require the model to have these three abilities. We specifically
  design these tasks to be synthetic and devoid of mathematical knowledge to ensure
  that only the fundamental reasoning biases can be learned from these tasks. This
  defines a new pre-training methodology called "LIME" (Learning Inductive bias for
  Mathematical rEasoning). Models trained with LIME significantly outperform vanilla
  transformers on four very different large mathematical reasoning benchmarks. Unlike
  dominating the computation cost as traditional pre-training approaches, LIME requires
  only a small fraction of the computation cost of the typical downstream task. The
  code for generating LIME tasks is available at https://github.com/tonywu95/LIME.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu21c
month: 0
tex_title: 'LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning'
firstpage: 11251
lastpage: 11262
page: 11251-11262
order: 11251
cycles: false
bibtex_author: Wu, Yuhuai and Rabe, Markus N and Li, Wenda and Ba, Jimmy and Grosse,
  Roger B and Szegedy, Christian
author:
- given: Yuhuai
  family: Wu
- given: Markus N
  family: Rabe
- given: Wenda
  family: Li
- given: Jimmy
  family: Ba
- given: Roger B
  family: Grosse
- given: Christian
  family: Szegedy
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wu21c/wu21c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/wu21c/wu21c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
