---
title: Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic MDPs
abstract: We consider model-free reinforcement learning (RL) in non-stationary Markov
  decision processes. Both the reward functions and the state transition functions
  are allowed to vary arbitrarily over time as long as their cumulative variations
  do not exceed certain variation budgets. We propose Restarted Q-Learning with Upper
  Confidence Bounds (RestartQ-UCB), the first model-free algorithm for non-stationary
  RL, and show that it outperforms existing solutions in terms of dynamic regret.
  Specifically, RestartQ-UCB with Freedman-type bonus terms achieves a dynamic regret
  bound of $\widetilde{O}(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}} H T^{\frac{2}{3}})$,
  where $S$ and $A$ are the numbers of states and actions, respectively, $\Delta>0$
  is the variation budget, $H$ is the number of time steps per episode, and $T$ is
  the total number of time steps. We further show that our algorithm is \emph{nearly
  optimal} by establishing an information-theoretical lower bound of $\Omega(S^{\frac{1}{3}}
  A^{\frac{1}{3}} \Delta^{\frac{1}{3}} H^{\frac{2}{3}} T^{\frac{2}{3}})$, the first
  lower bound in non-stationary RL. Numerical experiments validate the advantages
  of RestartQ-UCB in terms of both cumulative rewards and computational efficiency.
  We further demonstrate the power of our results in the context of multi-agent RL,
  where non-stationarity is a key challenge.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mao21b
month: 0
tex_title: Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic
  MDPs
firstpage: 7447
lastpage: 7458
page: 7447-7458
order: 7447
cycles: false
bibtex_author: Mao, Weichao and Zhang, Kaiqing and Zhu, Ruihao and Simchi-Levi, David
  and Basar, Tamer
author:
- given: Weichao
  family: Mao
- given: Kaiqing
  family: Zhang
- given: Ruihao
  family: Zhu
- given: David
  family: Simchi-Levi
- given: Tamer
  family: Basar
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/mao21b/mao21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/mao21b/mao21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
