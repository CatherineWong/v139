---
title: Accelerating Gossip SGD with Periodic Global Averaging
abstract: Communication overhead hinders the scalability of large-scale distributed
  training. Gossip SGD, where each node averages only with its neighbors, is more
  communication-efficient than the prevalent parallel SGD. However, its convergence
  rate is reversely proportional to quantity $1-\beta$ which measures the network
  connectivity. On large and sparse networks where $1-\beta \to 0$, Gossip SGD requires
  more iterations to converge, which offsets against its communication benefit. This
  paper introduces Gossip-PGA, which adds Periodic Global Averaging to accelerate
  Gossip SGD. Its transient stage, i.e., the iterations required to reach asymptotic
  linear speedup stage, improves from $\Omega(\beta^4 n^3/(1-\beta)^4)$ to $\Omega(\beta^4
  n^3 H^4)$ for non-convex problems. The influence of network topology in Gossip-PGA
  can be controlled by the averaging period $H$. Its transient-stage complexity is
  also superior to local SGD which has order $\Omega(n^3 H^4)$. Empirical results
  of large-scale training on image classification (ResNet50) and language modeling
  (BERT) validate our theoretical findings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen21y
month: 0
tex_title: Accelerating Gossip SGD with Periodic Global Averaging
firstpage: 1791
lastpage: 1802
page: 1791-1802
order: 1791
cycles: false
bibtex_author: Chen, Yiming and Yuan, Kun and Zhang, Yingya and Pan, Pan and Xu, Yinghui
  and Yin, Wotao
author:
- given: Yiming
  family: Chen
- given: Kun
  family: Yuan
- given: Yingya
  family: Zhang
- given: Pan
  family: Pan
- given: Yinghui
  family: Xu
- given: Wotao
  family: Yin
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/chen21y/chen21y.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/chen21y/chen21y-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
