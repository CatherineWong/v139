---
title: 'CATE: Computation-aware Neural Architecture Encoding with Transformers'
abstract: 'Recent works (White et al., 2020a; Yan et al., 2020) demonstrate the importance
  of architecture encodings in Neural Architecture Search (NAS). These encodings encode
  either structure or computation information of the neural architectures. Compared
  to structure-aware encodings, computation-aware encodings map architectures with
  similar accuracies to the same region, which improves the downstream architecture
  search performance (Zhang et al., 2019; White et al., 2020a). In this work, we introduce
  a Computation-Aware Transformer-based Encoding method called CATE. Different from
  existing computation-aware encodings based on fixed transformation (e.g. path encoding),
  CATE employs a pairwise pre-training scheme to learn computation-aware encodings
  using Transformers with cross-attention. Such learned encodings contain dense and
  contextualized computation information of neural architectures. We compare CATE
  with eleven encodings under three major encoding-dependent NAS subroutines in both
  small and large search spaces. Our experiments show that CATE is beneficial to the
  downstream search, especially in the large search space. Moreover, the outside search
  space experiment demonstrates its superior generalization ability beyond the search
  space on which it was trained. Our code is available at: https://github.com/MSU-MLSys-Lab/CATE.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan21c
month: 0
tex_title: 'CATE: Computation-aware Neural Architecture Encoding with Transformers'
firstpage: 11670
lastpage: 11681
page: 11670-11681
order: 11670
cycles: false
bibtex_author: Yan, Shen and Song, Kaiqiang and Liu, Fei and Zhang, Mi
author:
- given: Shen
  family: Yan
- given: Kaiqiang
  family: Song
- given: Fei
  family: Liu
- given: Mi
  family: Zhang
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/yan21c/yan21c.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v139/yan21c/yan21c-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
