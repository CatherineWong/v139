---
title: Training Recurrent Neural Networks via Forward Propagation Through Time
abstract: Back-propagation through time (BPTT) has been widely used for training Recurrent
  Neural Networks (RNNs). BPTT updates RNN parameters on an instance by back-propagating
  the error in time over the entire sequence length, and as a result, leads to poor
  trainability due to the well-known gradient explosion/decay phenomena. While a number
  of prior works have proposed to mitigate vanishing/explosion effect through careful
  RNN architecture design, these RNN variants still train with BPTT. We propose a
  novel forward-propagation algorithm, FPTT, where at each time, for an instance,
  we update RNN parameters by optimizing an instantaneous risk function. Our proposed
  risk is a regularization penalty at time $t$ that evolves dynamically based on previously
  observed losses, and allows for RNN parameter updates to converge to a stationary
  solution of the empirical RNN objective. We consider both sequence-to-sequence as
  well as terminal loss problems. Empirically FPTT outperforms BPTT on a number of
  well-known benchmark tasks, thus enabling architectures like LSTMs to solve long
  range dependencies problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kag21a
month: 0
tex_title: Training Recurrent Neural Networks via Forward Propagation Through Time
firstpage: 5189
lastpage: 5200
page: 5189-5200
order: 5189
cycles: false
bibtex_author: Kag, Anil and Saligrama, Venkatesh
author:
- given: Anil
  family: Kag
- given: Venkatesh
  family: Saligrama
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/kag21a/kag21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/kag21a/kag21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
