---
title: Lossless Compression of Efficient Private Local Randomizers
abstract: Locally Differentially Private (LDP) Reports are commonly used for collection
  of statistics and machine learning in the federated setting. In many cases the best
  known LDP algorithms require sending prohibitively large messages from the client
  device to the server (such as when constructing histograms over a large domain or
  learning a high-dimensional model). Here we demonstrate a general approach that,
  under standard cryptographic assumptions, compresses every efficient LDP algorithm
  with negligible loss in privacy and utility guarantees. The practical implication
  of our result is that in typical applications every message can be compressed to
  the size of the serverâ€™s pseudo-random generator seed. From this general approach
  we derive low-communication algorithms for the problems of frequency estimation
  and high-dimensional mean estimation. Our algorithms are simpler and more accurate
  than existing low-communication LDP algorithms for these well-studied problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feldman21a
month: 0
tex_title: Lossless Compression of Efficient Private Local Randomizers
firstpage: 3208
lastpage: 3219
page: 3208-3219
order: 3208
cycles: false
bibtex_author: Feldman, Vitaly and Talwar, Kunal
author:
- given: Vitaly
  family: Feldman
- given: Kunal
  family: Talwar
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/feldman21a/feldman21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/feldman21a/feldman21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
