---
title: Deeply-Debiased Off-Policy Interval Estimation
abstract: Off-policy evaluation learns a target policy’s value with a historical dataset
  generated by a different behavior policy. In addition to a point estimate, many
  applications would benefit significantly from having a confidence interval (CI)
  that quantifies the uncertainty of the point estimate. In this paper, we propose
  a novel procedure to construct an efficient, robust, and flexible CI on a target
  policy’s value. Our method is justified by theoretical results and numerical experiments.
  A Python implementation of the proposed procedure is available at https://github.com/
  RunzheStat/D2OPE.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shi21d
month: 0
tex_title: Deeply-Debiased Off-Policy Interval Estimation
firstpage: 9580
lastpage: 9591
page: 9580-9591
order: 9580
cycles: false
bibtex_author: Shi, Chengchun and Wan, Runzhe and Chernozhukov, Victor and Song, Rui
author:
- given: Chengchun
  family: Shi
- given: Runzhe
  family: Wan
- given: Victor
  family: Chernozhukov
- given: Rui
  family: Song
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/shi21d/shi21d.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v139/shi21d/shi21d-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
