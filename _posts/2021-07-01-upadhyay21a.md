---
title: A Framework for Private Matrix Analysis in Sliding Window Model
abstract: We perform a rigorous study of private matrix analysis when only the last
  $W$ updates to matrices are considered useful for analysis. We show the existing
  framework in the non-private setting is not robust to noise required for privacy.
  We then propose a framework robust to noise and use it to give first efficient $o(W)$
  space differentially private algorithms for spectral approximation, principal component
  analysis (PCA), multi-response linear regression, sparse PCA, and non-negative PCA.
  Prior to our work, no such result was known for sparse and non-negative differentially
  private PCA even in the static data setting. We also give a lower bound to demonstrate
  the cost of privacy in the sliding window model.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: upadhyay21a
month: 0
tex_title: A Framework for Private Matrix Analysis in Sliding Window Model
firstpage: 10465
lastpage: 10475
page: 10465-10475
order: 10465
cycles: false
bibtex_author: Upadhyay, Jalaj and Upadhyay, Sarvagya
author:
- given: Jalaj
  family: Upadhyay
- given: Sarvagya
  family: Upadhyay
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/upadhyay21a/upadhyay21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/upadhyay21a/upadhyay21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
