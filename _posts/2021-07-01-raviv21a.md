---
title: Enhancing Robustness of Neural Networks through Fourier Stabilization
abstract: Despite the considerable success of neural networks in security settings
  such as malware detection, such models have proved vulnerable to evasion attacks,
  in which attackers make slight changes to inputs (e.g., malware) to bypass detection.
  We propose a novel approach, Fourier stabilization, for designing evasion-robust
  neural networks with binary inputs. This approach, which is complementary to other
  forms of defense, replaces the weights of individual neurons with robust analogs
  derived using Fourier analytic tools. The choice of which neurons to stabilize in
  a neural network is then a combinatorial optimization problem, and we propose several
  methods for approximately solving it. We provide a formal bound on the per-neuron
  drop in accuracy due to Fourier stabilization, and experimentally demonstrate the
  effectiveness of the proposed approach in boosting robustness of neural networks
  in several detection settings. Moreover, we show that our approach effectively composes
  with adversarial training.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: raviv21a
month: 0
tex_title: Enhancing Robustness of Neural Networks through Fourier Stabilization
firstpage: 8880
lastpage: 8889
page: 8880-8889
order: 8880
cycles: false
bibtex_author: Raviv, Netanel and Kelley, Aidan and Guo, Minzhe and Vorobeychik, Yevgeniy
author:
- given: Netanel
  family: Raviv
- given: Aidan
  family: Kelley
- given: Minzhe
  family: Guo
- given: Yevgeniy
  family: Vorobeychik
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/raviv21a/raviv21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
