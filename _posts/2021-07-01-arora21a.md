---
title: 'Dropout: Explicit Forms and Capacity Control'
abstract: We investigate the capacity control provided by dropout in various machine
  learning problems. First, we study dropout for matrix completion, where it induces
  a distribution-dependent regularizer that equals the weighted trace-norm of the
  product of the factors. In deep learning, we show that the distribution-dependent
  regularizer due to dropout directly controls the Rademacher complexity of the underlying
  class of deep neural networks. These developments enable us to give concrete generalization
  error bounds for the dropout algorithm in both matrix completion as well as training
  deep neural networks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: arora21a
month: 0
tex_title: 'Dropout: Explicit Forms and Capacity Control'
firstpage: 351
lastpage: 361
page: 351-361
order: 351
cycles: false
bibtex_author: Arora, Raman and Bartlett, Peter and Mianjy, Poorya and Srebro, Nathan
author:
- given: Raman
  family: Arora
- given: Peter
  family: Bartlett
- given: Poorya
  family: Mianjy
- given: Nathan
  family: Srebro
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/arora21a/arora21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/arora21a/arora21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
