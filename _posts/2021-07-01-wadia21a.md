---
title: Whitening and Second Order Optimization Both Make Information in the Dataset
  Unusable During Training, and Can Reduce or Prevent Generalization
abstract: 'Machine learning is predicated on the concept of generalization: a model
  achieving low error on a sufficiently large training set should also perform well
  on novel samples from the same distribution. We show that both data whitening and
  second order optimization can harm or entirely prevent generalization. In general,
  model training harnesses information contained in the sample-sample second moment
  matrix of a dataset. For a general class of models, namely models with a fully connected
  first layer, we prove that the information contained in this matrix is the only
  information which can be used to generalize. Models trained using whitened data,
  or with certain second order optimization schemes, have less access to this information,
  resulting in reduced or nonexistent generalization ability. We experimentally verify
  these predictions for several architectures, and further demonstrate that generalization
  continues to be harmed even when theoretical requirements are relaxed. However,
  we also show experimentally that regularized second order optimization can provide
  a practical tradeoff, where training is accelerated but less information is lost,
  and generalization can in some circumstances even improve.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wadia21a
month: 0
tex_title: Whitening and Second Order Optimization Both Make Information in the Dataset
  Unusable During Training, and Can Reduce or Prevent Generalization
firstpage: 10617
lastpage: 10629
page: 10617-10629
order: 10617
cycles: false
bibtex_author: Wadia, Neha and Duckworth, Daniel and Schoenholz, Samuel S and Dyer,
  Ethan and Sohl-Dickstein, Jascha
author:
- given: Neha
  family: Wadia
- given: Daniel
  family: Duckworth
- given: Samuel S
  family: Schoenholz
- given: Ethan
  family: Dyer
- given: Jascha
  family: Sohl-Dickstein
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wadia21a/wadia21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/wadia21a/wadia21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
