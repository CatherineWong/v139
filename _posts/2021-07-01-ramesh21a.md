---
title: Zero-Shot Text-to-Image Generation
abstract: Text-to-image generation has traditionally focused on finding better modeling
  assumptions for training on a fixed dataset. These assumptions might involve complex
  architectures, auxiliary losses, or side information such as object part labels
  or segmentation masks supplied during training. We describe a simple approach for
  this task based on a transformer that autoregressively models the text and image
  tokens as a single stream of data. With sufficient data and scale, our approach
  is competitive with previous domain-specific models when evaluated in a zero-shot
  fashion.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ramesh21a
month: 0
tex_title: Zero-Shot Text-to-Image Generation
firstpage: 8821
lastpage: 8831
page: 8821-8831
order: 8821
cycles: false
bibtex_author: Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott
  and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya
author:
- given: Aditya
  family: Ramesh
- given: Mikhail
  family: Pavlov
- given: Gabriel
  family: Goh
- given: Scott
  family: Gray
- given: Chelsea
  family: Voss
- given: Alec
  family: Radford
- given: Mark
  family: Chen
- given: Ilya
  family: Sutskever
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
