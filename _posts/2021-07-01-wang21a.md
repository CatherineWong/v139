---
title: Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model
abstract: Knowledge distillation (KD) is a successful approach for deep neural network
  acceleration, with which a compact network (student) is trained by mimicking the
  softmax output of a pre-trained high-capacity network (teacher). In tradition, KD
  usually relies on access to the training samples and the parameters of the white-box
  teacher to acquire the transferred knowledge. However, these prerequisites are not
  always realistic due to storage costs or privacy issues in real-world applications.
  Here we propose the concept of decision-based black-box (DB3) knowledge distillation,
  with which the student is trained by distilling the knowledge from a black-box teacher
  (parameters are not accessible) that only returns classes rather than softmax outputs.
  We start with the scenario when the training set is accessible. We represent a sample’s
  robustness against other classes by computing its distances to the teacher’s decision
  boundaries and use it to construct the soft label for each training sample. After
  that, the student can be trained via standard KD. We then extend this approach to
  a more challenging scenario in which even accessing the training data is not feasible.
  We propose to generate pseudo samples that are distinguished by the decision boundaries
  of the DB3 teacher to the largest extent and construct soft labels for these samples,
  which are used as the transfer set. We evaluate our approaches on various benchmark
  networks and datasets and experiment results demonstrate their effectiveness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21a
month: 0
tex_title: Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model
firstpage: 10675
lastpage: 10685
page: 10675-10685
order: 10675
cycles: false
bibtex_author: Wang, Zi
author:
- given: Zi
  family: Wang
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wang21a/wang21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/wang21a/wang21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
