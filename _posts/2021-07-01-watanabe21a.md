---
title: A Unified Generative Adversarial Network Training via Self-Labeling and Self-Attention
abstract: We propose a novel GAN training scheme that can handle any level of labeling
  in a unified manner. Our scheme introduces a form of artificial labeling that can
  incorporate manually defined labels, when available, and induce an alignment between
  them. To define the artificial labels, we exploit the assumption that neural network
  generators can be trained more easily to map nearby latent vectors to data with
  semantic similarities, than across separate categories. We use generated data samples
  and their corresponding artificial conditioning labels to train a classifier. The
  classifier is then used to self-label real data. To boost the accuracy of the self-labeling,
  we also use the exponential moving average of the classifier. However, because the
  classifier might still make mistakes, especially at the beginning of the training,
  we also refine the labels through self-attention, by using the labeling of real
  data samples only when the classifier outputs a high classification probability
  score. We evaluate our approach on CIFAR-10, STL-10 and SVHN, and show that both
  self-labeling and self-attention consistently improve the quality of generated data.
  More surprisingly, we find that the proposed scheme can even outperform class-conditional
  GANs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: watanabe21a
month: 0
tex_title: A Unified Generative Adversarial Network Training via Self-Labeling and
  Self-Attention
firstpage: 11024
lastpage: 11034
page: 11024-11034
order: 11024
cycles: false
bibtex_author: Watanabe, Tomoki and Favaro, Paolo
author:
- given: Tomoki
  family: Watanabe
- given: Paolo
  family: Favaro
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/watanabe21a/watanabe21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
