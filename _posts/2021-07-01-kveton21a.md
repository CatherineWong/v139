---
title: Meta-Thompson Sampling
abstract: Efficient exploration in bandits is a fundamental online learning problem.
  We propose a variant of Thompson sampling that learns to explore better as it interacts
  with bandit instances drawn from an unknown prior. The algorithm meta-learns the
  prior and thus we call it MetaTS. We propose several efficient implementations of
  MetaTS and analyze it in Gaussian bandits. Our analysis shows the benefit of meta-learning
  and is of a broader interest, because we derive a novel prior-dependent Bayes regret
  bound for Thompson sampling. Our theory is complemented by empirical evaluation,
  which shows that MetaTS quickly adapts to the unknown prior.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kveton21a
month: 0
tex_title: Meta-Thompson Sampling
firstpage: 5884
lastpage: 5893
page: 5884-5893
order: 5884
cycles: false
bibtex_author: Kveton, Branislav and Konobeev, Mikhail and Zaheer, Manzil and Hsu,
  Chih-Wei and Mladenov, Martin and Boutilier, Craig and Szepesvari, Csaba
author:
- given: Branislav
  family: Kveton
- given: Mikhail
  family: Konobeev
- given: Manzil
  family: Zaheer
- given: Chih-Wei
  family: Hsu
- given: Martin
  family: Mladenov
- given: Craig
  family: Boutilier
- given: Csaba
  family: Szepesvari
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/kveton21a/kveton21a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v139/kveton21a/kveton21a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
