---
title: Mixed Cross Entropy Loss for Neural Machine Translation
abstract: In neural machine translation, Cross Entropy loss (CE) is the standard loss
  function in two training methods of auto-regressive models, i.e., teacher forcing
  and scheduled sampling. In this paper, we propose mixed Cross Entropy loss (mixed
  CE) as a substitute for CE in both training approaches. In teacher forcing, the
  model trained with CE regards the translation problem as a one-to-one mapping process,
  while in mixed CE this process can be relaxed to one-to-many. In scheduled sampling,
  we show that mixed CE has the potential to encourage the training and testing behaviours
  to be similar to each other, more effectively mitigating the exposure bias problem.
  We demonstrate the superiority of mixed CE over CE on several machine translation
  datasets, WMT’16 Ro-En, WMT’16 Ru-En, and WMT’14 En-De in both teacher forcing and
  scheduled sampling setups. Furthermore, in WMT’14 En-De, we also find mixed CE consistently
  outperforms CE on a multi-reference set as well as a challenging paraphrased reference
  set. We also found the model trained with mixed CE is able to provide a better probability
  distribution defined over the translation output space. Our code is available at
  https://github.com/haorannlp/mix.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li21n
month: 0
tex_title: Mixed Cross Entropy Loss for Neural Machine Translation
firstpage: 6425
lastpage: 6436
page: 6425-6436
order: 6425
cycles: false
bibtex_author: Li, Haoran and Lu, Wei
author:
- given: Haoran
  family: Li
- given: Wei
  family: Lu
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/li21n/li21n.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/li21n/li21n-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
