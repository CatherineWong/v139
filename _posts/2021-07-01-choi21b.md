---
title: Variational Empowerment as Representation Learning for Goal-Conditioned Reinforcement
  Learning
abstract: Learning to reach goal states and learning diverse skills through mutual
  information maximization have been proposed as principled frameworks for unsupervised
  reinforcement learning, allowing agents to acquire broadly applicable multi-task
  policies with minimal reward engineering. In this paper, we discuss how these two
  approaches {—} goal-conditioned RL (GCRL) and MI-based RL {—} can be generalized
  into a single family of methods, interpreting mutual information maximization and
  variational empowerment as representation learning methods that acquire function-ally
  aware state representations for goal reaching.Starting from a simple observation
  that the standard GCRL is encapsulated by the optimization objective of variational
  empowerment, we can derive novel variants of GCRL and variational empowerment under
  a single, unified optimization objective, such as adaptive-variance GCRL and linear-mapping
  GCRL, and study the characteristics of representation learning each variant provides.
  Furthermore, through the lens of GCRL, we show that adapting powerful techniques
  fromGCRL such as goal relabeling into the variationalMI context as well as proper
  regularization on the variational posterior provides substantial gains in algorithm
  performance, and propose a novel evaluation metric named latent goal reaching (LGR)as
  an objective measure for evaluating empowerment algorithms akin to goal-based RL.
  Through principled mathematical derivations and careful experimental validations,
  our work lays a novel foundation from which representation learning can be evaluated
  and analyzed in goal-based RL
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: choi21b
month: 0
tex_title: Variational Empowerment as Representation Learning for Goal-Conditioned
  Reinforcement Learning
firstpage: 1953
lastpage: 1963
page: 1953-1963
order: 1953
cycles: false
bibtex_author: Choi, Jongwook and Sharma, Archit and Lee, Honglak and Levine, Sergey
  and Gu, Shixiang Shane
author:
- given: Jongwook
  family: Choi
- given: Archit
  family: Sharma
- given: Honglak
  family: Lee
- given: Sergey
  family: Levine
- given: Shixiang Shane
  family: Gu
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/choi21b/choi21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/choi21b/choi21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
