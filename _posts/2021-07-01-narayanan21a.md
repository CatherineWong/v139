---
title: Memory-Efficient Pipeline-Parallel DNN Training
abstract: Many state-of-the-art ML results have been obtained by scaling up the number
  of parameters in existing models. However, parameters and activations for such large
  models often do not fit in the memory of a single accelerator device; this means
  that it is necessary to distribute training of large models over multiple accelerators.
  In this work, we propose PipeDream-2BW, a system that supports memory-efficient
  pipeline parallelism. PipeDream-2BW uses a novel pipelining and weight gradient
  coalescing strategy, combined with the double buffering of weights, to ensure high
  throughput, low memory footprint, and weight update semantics similar to data parallelism.
  In addition, PipeDream-2BW automatically partitions the model over the available
  hardware resources, while respecting hardware constraints such as memory capacities
  of accelerators and interconnect topologies. PipeDream-2BW can accelerate the training
  of large GPT and BERT language models by up to 20x with similar final model accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: narayanan21a
month: 0
tex_title: Memory-Efficient Pipeline-Parallel DNN Training
firstpage: 7937
lastpage: 7947
page: 7937-7947
order: 7937
cycles: false
bibtex_author: Narayanan, Deepak and Phanishayee, Amar and Shi, Kaiyu and Chen, Xie
  and Zaharia, Matei
author:
- given: Deepak
  family: Narayanan
- given: Amar
  family: Phanishayee
- given: Kaiyu
  family: Shi
- given: Xie
  family: Chen
- given: Matei
  family: Zaharia
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/narayanan21a/narayanan21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/narayanan21a/narayanan21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
