---
title: 'Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning'
abstract: 'Reinforcement Learning in large action spaces is a challenging problem.
  This is especially true for cooperative multi-agent reinforcement learning (MARL),
  which often requires tractable learning while respecting various constraints like
  communication budget and information about other agents. In this work, we focus
  on the fundamental hurdle affecting both value-based and policy-gradient approaches:
  an exponential blowup of the action space with the number of agents. For value-based
  methods, it poses challenges in accurately representing the optimal value function
  for value-based methods, thus inducing suboptimality. For policy gradient methods,
  it renders the critic ineffective and exacerbates the problem of the lagging critic.
  We show that from a learning theory perspective, both problems can be addressed
  by accurately representing the associated action-value function with a low-complexity
  hypothesis class. This requires accurately modelling the agent interactions in a
  sample efficient way. To this end, we propose a novel tensorised formulation of
  the Bellman equation. This gives rise to our method Tesseract, which utilises the
  view of Q-function seen as a tensor where the modes correspond to action spaces
  of different agents. Algorithms derived from Tesseract decompose the Q-tensor across
  the agents and utilise low-rank tensor approximations to model the agent interactions
  relevant to the task. We provide PAC analysis for Tesseract based algorithms and
  highlight their relevance to the class of rich observation MDPs. Empirical results
  in different domains confirm the gains in sample efficiency using Tesseract as supported
  by the theory.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mahajan21a
month: 0
tex_title: 'Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning'
firstpage: 7301
lastpage: 7312
page: 7301-7312
order: 7301
cycles: false
bibtex_author: Mahajan, Anuj and Samvelyan, Mikayel and Mao, Lei and Makoviychuk,
  Viktor and Garg, Animesh and Kossaifi, Jean and Whiteson, Shimon and Zhu, Yuke and
  Anandkumar, Animashree
author:
- given: Anuj
  family: Mahajan
- given: Mikayel
  family: Samvelyan
- given: Lei
  family: Mao
- given: Viktor
  family: Makoviychuk
- given: Animesh
  family: Garg
- given: Jean
  family: Kossaifi
- given: Shimon
  family: Whiteson
- given: Yuke
  family: Zhu
- given: Animashree
  family: Anandkumar
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/mahajan21a/mahajan21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/mahajan21a/mahajan21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
