---
title: Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators
  with $\sqrt$T Regret
abstract: We consider the task of learning to control a linear dynamical system under
  fixed quadratic costs, known as the Linear Quadratic Regulator (LQR) problem. While
  model-free approaches are often favorable in practice, thus far only model-based
  methods, which rely on costly system identification, have been shown to achieve
  regret that scales with the optimal dependence on the time horizon T. We present
  the first model-free algorithm that achieves similar regret guarantees. Our method
  relies on an efficient policy gradient scheme, and a novel and tighter analysis
  of the cost of exploration in policy space in this setting.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cassel21a
month: 0
tex_title: Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators
  with $\sqrt{}$T Regret
firstpage: 1304
lastpage: 1313
page: 1304-1313
order: 1304
cycles: false
bibtex_author: Cassel, Asaf B and Koren, Tomer
author:
- given: Asaf B
  family: Cassel
- given: Tomer
  family: Koren
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/cassel21a/cassel21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
