---
title: Variational Auto-Regressive Gaussian Processes for Continual Learning
abstract: Through sequential construction of posteriors on observing data online,
  Bayesâ€™ theorem provides a natural framework for continual learning. We develop Variational
  Auto-Regressive Gaussian Processes (VAR-GPs), a principled posterior updating mechanism
  to solve sequential tasks in continual learning. By relying on sparse inducing point
  approximations for scalable posteriors, we propose a novel auto-regressive variational
  distribution which reveals two fruitful connections to existing results in Bayesian
  inference, expectation propagation and orthogonal inducing points. Mean predictive
  entropy estimates show VAR-GPs prevent catastrophic forgetting, which is empirically
  supported by strong performance on modern continual learning benchmarks against
  competitive baselines. A thorough ablation study demonstrates the efficacy of our
  modeling choices.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kapoor21b
month: 0
tex_title: Variational Auto-Regressive Gaussian Processes for Continual Learning
firstpage: 5290
lastpage: 5300
page: 5290-5300
order: 5290
cycles: false
bibtex_author: Kapoor, Sanyam and Karaletsos, Theofanis and Bui, Thang D
author:
- given: Sanyam
  family: Kapoor
- given: Theofanis
  family: Karaletsos
- given: Thang D
  family: Bui
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/kapoor21b/kapoor21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/kapoor21b/kapoor21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
