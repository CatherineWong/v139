---
title: Fairness of Exposure in Stochastic Bandits
abstract: Contextual bandit algorithms have become widely used for recommendation
  in online systems (e.g. marketplaces, music streaming, news), where they now wield
  substantial influence on which items get shown to users. This raises questions of
  fairness to the items â€” and to the sellers, artists, and writers that benefit from
  this exposure. We argue that the conventional bandit formulation can lead to an
  undesirable and unfair winner-takes-all allocation of exposure. To remedy this problem,
  we propose a new bandit objective that guarantees merit-based fairness of exposure
  to the items while optimizing utility to the users. We formulate fairness regret
  and reward regret in this setting and present algorithms for both stochastic multi-armed
  bandits and stochastic linear bandits. We prove that the algorithms achieve sublinear
  fairness regret and reward regret. Beyond the theoretical analysis, we also provide
  empirical evidence that these algorithms can allocate exposure to different arms
  effectively.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21b
month: 0
tex_title: Fairness of Exposure in Stochastic Bandits
firstpage: 10686
lastpage: 10696
page: 10686-10696
order: 10686
cycles: false
bibtex_author: Wang, Lequn and Bai, Yiwei and Sun, Wen and Joachims, Thorsten
author:
- given: Lequn
  family: Wang
- given: Yiwei
  family: Bai
- given: Wen
  family: Sun
- given: Thorsten
  family: Joachims
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wang21b/wang21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/wang21b/wang21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
