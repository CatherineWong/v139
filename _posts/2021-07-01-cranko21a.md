---
title: Generalised Lipschitz Regularisation Equals Distributional Robustness
abstract: The problem of adversarial examples has highlighted the need for a theory
  of regularisation that is general enough to apply to exotic function classes, such
  as universal approximators. In response, we have been able to significantly sharpen
  existing results regarding the relationship between distributional robustness and
  regularisation, when defined with a transportation cost uncertainty set. The theory
  allows us to characterise the conditions under which the distributional robustness
  equals a Lipschitz-regularised model, and to tightly quantify, for the first time,
  the slackness under very mild assumptions. As a theoretical application we show
  a new result explicating the connection between adversarial learning and distributional
  robustness. We then give new results for how to achieve Lipschitz regularisation
  of kernel classifiers, which are demonstrated experimentally.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cranko21a
month: 0
tex_title: Generalised Lipschitz Regularisation Equals Distributional Robustness
firstpage: 2178
lastpage: 2188
page: 2178-2188
order: 2178
cycles: false
bibtex_author: Cranko, Zac and Shi, Zhan and Zhang, Xinhua and Nock, Richard and Kornblith,
  Simon
author:
- given: Zac
  family: Cranko
- given: Zhan
  family: Shi
- given: Xinhua
  family: Zhang
- given: Richard
  family: Nock
- given: Simon
  family: Kornblith
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/cranko21a/cranko21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/cranko21a/cranko21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
