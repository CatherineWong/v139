---
title: Tractable structured natural-gradient descent using local parameterizations
abstract: Natural-gradient descent (NGD) on structured parameter spaces (e.g., low-rank
  covariances) is computationally challenging due to difficult Fisher-matrix computations.
  We address this issue by using \emph{local-parameter coordinates} to obtain a flexible
  and efficient NGD method that works well for a wide-variety of structured parameterizations.
  We show four applications where our method (1) generalizes the exponential natural
  evolutionary strategy, (2) recovers existing Newton-like algorithms, (3) yields
  new structured second-order algorithms, and (4) gives new algorithms to learn covariances
  of Gaussian and Wishart-based distributions. We show results on a range of problems
  from deep learning, variational inference, and evolution strategies. Our work opens
  a new direction for scalable structured geometric methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin21e
month: 0
tex_title: Tractable structured natural-gradient descent using local parameterizations
firstpage: 6680
lastpage: 6691
page: 6680-6691
order: 6680
cycles: false
bibtex_author: Lin, Wu and Nielsen, Frank and Emtiyaz, Khan Mohammad and Schmidt,
  Mark
author:
- given: Wu
  family: Lin
- given: Frank
  family: Nielsen
- given: Khan Mohammad
  family: Emtiyaz
- given: Mark
  family: Schmidt
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/lin21e/lin21e.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/lin21e/lin21e-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
