---
title: 'Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient
  Exploration'
abstract: In this paper, sample-aware policy entropy regularization is proposed to
  enhance the conventional policy entropy regularization for better exploration. Exploiting
  the sample distribution obtainable from the replay buffer, the proposed sample-aware
  entropy regularization maximizes the entropy of the weighted sum of the policy action
  distribution and the sample action distribution from the replay buffer for sample-efficient
  exploration. A practical algorithm named diversity actor-critic (DAC) is developed
  by applying policy iteration to the objective function with the proposed sample-aware
  entropy regularization. Numerical results show that DAC significantly outperforms
  existing recent algorithms for reinforcement learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: han21a
month: 0
tex_title: 'Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient
  Exploration'
firstpage: 4018
lastpage: 4029
page: 4018-4029
order: 4018
cycles: false
bibtex_author: Han, Seungyul and Sung, Youngchul
author:
- given: Seungyul
  family: Han
- given: Youngchul
  family: Sung
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/han21a/han21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/han21a/han21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
