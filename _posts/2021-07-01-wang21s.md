---
title: 'SketchEmbedNet: Learning Novel Concepts by Imitating Drawings'
abstract: Sketch drawings capture the salient information of visual concepts. Previous
  work has shown that neural networks are capable of producing sketches of natural
  objects drawn from a small number of classes. While earlier approaches focus on
  generation quality or retrieval, we explore properties of image representations
  learned by training a model to produce sketches of images. We show that this generative,
  class-agnostic model produces informative embeddings of images from novel examples,
  classes, and even novel datasets in a few-shot setting. Additionally, we find that
  these learned representations exhibit interesting structure and compositionality.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21s
month: 0
tex_title: 'SketchEmbedNet: Learning Novel Concepts by Imitating Drawings'
firstpage: 10870
lastpage: 10881
page: 10870-10881
order: 10870
cycles: false
bibtex_author: Wang, Alexander and Ren, Mengye and Zemel, Richard
author:
- given: Alexander
  family: Wang
- given: Mengye
  family: Ren
- given: Richard
  family: Zemel
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wang21s/wang21s.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v139/wang21s/wang21s-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
