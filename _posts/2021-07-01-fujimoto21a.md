---
title: A Deep Reinforcement Learning Approach to Marginalized Importance Sampling
  with the Successor Representation
abstract: Marginalized importance sampling (MIS), which measures the density ratio
  between the state-action occupancy of a target policy and that of a sampling distribution,
  is a promising approach for off-policy evaluation. However, current state-of-the-art
  MIS methods rely on complex optimization tricks and succeed mostly on simple toy
  problems. We bridge the gap between MIS and deep reinforcement learning by observing
  that the density ratio can be computed from the successor representation of the
  target policy. The successor representation can be trained through deep reinforcement
  learning methodology and decouples the reward optimization from the dynamics of
  the environment, making the resulting algorithm stable and applicable to high-dimensional
  domains. We evaluate the empirical performance of our approach on a variety of challenging
  Atari and MuJoCo environments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fujimoto21a
month: 0
tex_title: A Deep Reinforcement Learning Approach to Marginalized Importance Sampling
  with the Successor Representation
firstpage: 3518
lastpage: 3529
page: 3518-3529
order: 3518
cycles: false
bibtex_author: Fujimoto, Scott and Meger, David and Precup, Doina
author:
- given: Scott
  family: Fujimoto
- given: David
  family: Meger
- given: Doina
  family: Precup
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/fujimoto21a/fujimoto21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/fujimoto21a/fujimoto21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
