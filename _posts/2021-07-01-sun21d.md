---
title: Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition
abstract: We introduce a new scalable variational Gaussian process approximation which
  provides a high fidelity approximation while retaining general applicability. We
  propose the harmonic kernel decomposition (HKD), which uses Fourier series to decompose
  a kernel as a sum of orthogonal kernels. Our variational approximation exploits
  this orthogonality to enable a large number of inducing points at a low computational
  cost. We demonstrate that, on a range of regression and classification problems,
  our approach can exploit input space symmetries such as translations and reflections,
  and it significantly outperforms standard variational methods in scalability and
  accuracy. Notably, our approach achieves state-of-the-art results on CIFAR-10 among
  pure GP models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sun21d
month: 0
tex_title: Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition
firstpage: 9955
lastpage: 9965
page: 9955-9965
order: 9955
cycles: false
bibtex_author: Sun, Shengyang and Shi, Jiaxin and Wilson, Andrew Gordon Gordon and
  Grosse, Roger B
author:
- given: Shengyang
  family: Sun
- given: Jiaxin
  family: Shi
- given: Andrew Gordon Gordon
  family: Wilson
- given: Roger B
  family: Grosse
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/sun21d/sun21d.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/sun21d/sun21d-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
