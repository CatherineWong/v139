---
title: Addressing Catastrophic Forgetting in Few-Shot Problems
abstract: Neural networks are known to suffer from catastrophic forgetting when trained
  on sequential datasets. While there have been numerous attempts to solve this problem
  in large-scale supervised classification, little has been done to overcome catastrophic
  forgetting in few-shot classification problems. We demonstrate that the popular
  gradient-based model-agnostic meta-learning algorithm (MAML) indeed suffers from
  catastrophic forgetting and introduce a Bayesian online meta-learning framework
  that tackles this problem. Our framework utilises Bayesian online learning and meta-learning
  along with Laplace approximation and variational inference to overcome catastrophic
  forgetting in few-shot classification problems. The experimental evaluations demonstrate
  that our framework can effectively achieve this goal in comparison with various
  baselines. As an additional utility, we also demonstrate empirically that our framework
  is capable of meta-learning on sequentially arriving few-shot tasks from a stationary
  task distribution.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yap21a
month: 0
tex_title: Addressing Catastrophic Forgetting in Few-Shot Problems
firstpage: 11909
lastpage: 11919
page: 11909-11919
order: 11909
cycles: false
bibtex_author: Yap, Pauching and Ritter, Hippolyt and Barber, David
author:
- given: Pauching
  family: Yap
- given: Hippolyt
  family: Ritter
- given: David
  family: Barber
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/yap21a/yap21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/yap21a/yap21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
