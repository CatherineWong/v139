---
title: 'Best Model Identification: A Rested Bandit Formulation'
abstract: We introduce and analyze a best arm identification problem in the rested
  bandit setting, wherein arms are themselves learning algorithms whose expected losses
  decrease with the number of times the arm has been played. The shape of the expected
  loss functions is similar across arms, and is assumed to be available up to unknown
  parameters that have to be learned on the fly. We define a novel notion of regret
  for this problem, where we compare to the policy that always plays the arm having
  the smallest expected loss at the end of the game. We analyze an arm elimination
  algorithm whose regret vanishes as the time horizon increases. The actual rate of
  convergence depends in a detailed way on the postulated functional form of the expected
  losses. We complement our analysis with lower bounds, indicating strengths and limitations
  of the proposed solution.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cella21a
month: 0
tex_title: 'Best Model Identification: A Rested Bandit Formulation'
firstpage: 1362
lastpage: 1372
page: 1362-1372
order: 1362
cycles: false
bibtex_author: Cella, Leonardo and Pontil, Massimiliano and Gentile, Claudio
author:
- given: Leonardo
  family: Cella
- given: Massimiliano
  family: Pontil
- given: Claudio
  family: Gentile
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/cella21a/cella21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/cella21a/cella21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
