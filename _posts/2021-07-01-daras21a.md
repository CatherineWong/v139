---
title: Intermediate Layer Optimization for Inverse Problems using Deep Generative
  Models
abstract: We propose Intermediate Layer Optimization (ILO), a novel optimization algorithm
  for solving inverse problems with deep generative models. Instead of optimizing
  only over the initial latent code, we progressively change the input layer obtaining
  successively more expressive generators. To explore the higher dimensional spaces,
  our method searches for latent codes that lie within a small l1 ball around the
  manifold induced by the previous layer. Our theoretical analysis shows that by keeping
  the radius of the ball relatively small, we can improve the established error bound
  for compressed sensing with deep generative models. We empirically show that our
  approach outperforms state-of-the-art methods introduced in StyleGAN2 and PULSE
  for a wide range of inverse problems including inpainting, denoising, super-resolution
  and compressed sensing.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: daras21a
month: 0
tex_title: Intermediate Layer Optimization for Inverse Problems using Deep Generative
  Models
firstpage: 2421
lastpage: 2432
page: 2421-2432
order: 2421
cycles: false
bibtex_author: Daras, Giannis and Dean, Joseph and Jalal, Ajil and Dimakis, Alex
author:
- given: Giannis
  family: Daras
- given: Joseph
  family: Dean
- given: Ajil
  family: Jalal
- given: Alex
  family: Dimakis
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/daras21a/daras21a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v139/daras21a/daras21a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
