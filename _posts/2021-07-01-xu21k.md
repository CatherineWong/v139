---
title: 'Optimization of Graph Neural Networks: Implicit Acceleration by Skip Connections
  and More Depth'
abstract: Graph Neural Networks (GNNs) have been studied through the lens of expressive
  power and generalization. However, their optimization properties are less well understood.
  We take the first step towards analyzing GNN training by studying the gradient dynamics
  of GNNs. First, we analyze linearized GNNs and prove that despite the non-convexity
  of training, convergence to a global minimum at a linear rate is guaranteed under
  mild assumptions that we validate on real-world graphs. Second, we study what may
  affect the GNNsâ€™ training speed. Our results show that the training of GNNs is implicitly
  accelerated by skip connections, more depth, and/or a good label distribution. Empirical
  results confirm that our theoretical results for linearized GNNs align with the
  training behavior of nonlinear GNNs. Our results provide the first theoretical support
  for the success of GNNs with skip connections in terms of optimization, and suggest
  that deep GNNs with skip connections would be promising in practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu21k
month: 0
tex_title: 'Optimization of Graph Neural Networks: Implicit Acceleration by Skip Connections
  and More Depth'
firstpage: 11592
lastpage: 11602
page: 11592-11602
order: 11592
cycles: false
bibtex_author: Xu, Keyulu and Zhang, Mozhi and Jegelka, Stefanie and Kawaguchi, Kenji
author:
- given: Keyulu
  family: Xu
- given: Mozhi
  family: Zhang
- given: Stefanie
  family: Jegelka
- given: Kenji
  family: Kawaguchi
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/xu21k/xu21k.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/xu21k/xu21k-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
