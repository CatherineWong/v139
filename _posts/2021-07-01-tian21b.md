---
title: Online Learning in Unknown Markov Games
abstract: We study online learning in unknown Markov games, a problem that arises
  in episodic multi-agent reinforcement learning where the actions of the opponents
  are unobservable. We show that in this challenging setting, achieving sublinear
  regret against the best response in hindsight is statistically hard. We then consider
  a weaker notion of regret by competing with the \emph{minimax value} of the game,
  and present an algorithm that achieves a sublinear $\tilde{\mathcal{O}}(K^{2/3})$
  regret after $K$ episodes. This is the first sublinear regret bound (to our knowledge)
  for online learning in unknown Markov games. Importantly, our regret bound is independent
  of the size of the opponents’ action spaces. As a result, even when the opponents’
  actions are fully observable, our regret bound improves upon existing analysis (e.g.,
  (Xie et al., 2020)) by an exponential factor in the number of opponents.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tian21b
month: 0
tex_title: Online Learning in Unknown Markov Games
firstpage: 10279
lastpage: 10288
page: 10279-10288
order: 10279
cycles: false
bibtex_author: Tian, Yi and Wang, Yuanhao and Yu, Tiancheng and Sra, Suvrit
author:
- given: Yi
  family: Tian
- given: Yuanhao
  family: Wang
- given: Tiancheng
  family: Yu
- given: Suvrit
  family: Sra
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/tian21b/tian21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/tian21b/tian21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
