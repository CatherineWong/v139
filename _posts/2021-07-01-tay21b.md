---
title: 'OmniNet: Omnidirectional Representations from Transformers'
abstract: This paper proposes Omnidirectional Representations from Transformers (OMNINET).
  In OmniNet, instead of maintaining a strictly horizon-tal receptive field, each
  token is allowed to attend to all tokens in the entire network. This process can
  also be interpreted as a form of extreme or intensive attention mechanism that has
  the receptive field of the entire width and depth of the network. To this end, the
  omnidirectional attention is learned via a meta-learner, which is essentially another
  self-attention based model. In order to mitigate the computationally expensive costs
  of full receptive field attention, we leverage efficient self-attention models such
  as kernel-based, low-rank attention and/or Big Bird as the meta-learner. Extensive
  experiments are conducted on autoregressive language modeling(LM1B, C4), Machine
  Translation, Long Range Arena (LRA), and Image Recognition.The experiments show
  that OmniNet achieves considerable improvements across these tasks, including achieving
  state-of-the-art performance on LM1B,WMTâ€™14 En-De/En-Fr, and Long Range Arena.Moreover,
  using omnidirectional representation in Vision Transformers leads to significant
  improvements on image recognition tasks on both few-shot learning and fine-tuning
  setups.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tay21b
month: 0
tex_title: 'OmniNet: Omnidirectional Representations from Transformers'
firstpage: 10193
lastpage: 10202
page: 10193-10202
order: 10193
cycles: false
bibtex_author: Tay, Yi and Dehghani, Mostafa and Aribandi, Vamsi and Gupta, Jai and
  Pham, Philip M and Qin, Zhen and Bahri, Dara and Juan, Da-Cheng and Metzler, Donald
author:
- given: Yi
  family: Tay
- given: Mostafa
  family: Dehghani
- given: Vamsi
  family: Aribandi
- given: Jai
  family: Gupta
- given: Philip M
  family: Pham
- given: Zhen
  family: Qin
- given: Dara
  family: Bahri
- given: Da-Cheng
  family: Juan
- given: Donald
  family: Metzler
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/tay21b/tay21b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
