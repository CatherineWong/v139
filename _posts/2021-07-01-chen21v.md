---
title: Overcoming Catastrophic Forgetting by Bayesian Generative Regularization
abstract: In this paper, we propose a new method to over-come catastrophic forgetting
  by adding generative regularization to Bayesian inference frame-work. Bayesian method
  provides a general frame-work for continual learning. We could further construct
  a generative regularization term for all given classification models by leveraging
  energy-based models and Langevin dynamic sampling to enrich the features learned
  in each task. By combining discriminative and generative loss together, we empirically
  show that the proposed method outperforms state-of-the-art methods on a variety
  of tasks, avoiding catastrophic forgetting in continual learning. In particular,
  the proposed method outperforms baseline methods over 15%on the Fashion-MNIST dataset
  and 10%on the CUB dataset.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen21v
month: 0
tex_title: Overcoming Catastrophic Forgetting by Bayesian Generative Regularization
firstpage: 1760
lastpage: 1770
page: 1760-1770
order: 1760
cycles: false
bibtex_author: Chen, Pei-Hung and Wei, Wei and Hsieh, Cho-Jui and Dai, Bo
author:
- given: Pei-Hung
  family: Chen
- given: Wei
  family: Wei
- given: Cho-Jui
  family: Hsieh
- given: Bo
  family: Dai
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/chen21v/chen21v.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/chen21v/chen21v-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
