---
title: Robust Reinforcement Learning using Least Squares Policy Iteration with Provable
  Performance Guarantees
abstract: This paper addresses the problem of model-free reinforcement learning for
  Robust Markov Decision Process (RMDP) with large state spaces. The goal of the RMDPs
  framework is to find a policy that is robust against the parameter uncertainties
  due to the mismatch between the simulator model and real-world settings. We first
  propose the Robust Least Squares Policy Evaluation algorithm, which is a multi-step
  online model-free learning algorithm for policy evaluation. We prove the convergence
  of this algorithm using stochastic approximation techniques. We then propose Robust
  Least Squares Policy Iteration (RLSPI) algorithm for learning the optimal robust
  policy. We also give a general weighted Euclidean norm bound on the error (closeness
  to optimality) of the resulting policy. Finally, we demonstrate the performance
  of our RLSPI algorithm on some benchmark problems from OpenAI Gym.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: badrinath21a
month: 0
tex_title: Robust Reinforcement Learning using Least Squares Policy Iteration with
  Provable Performance Guarantees
firstpage: 511
lastpage: 520
page: 511-520
order: 511
cycles: false
bibtex_author: Badrinath, Kishan Panaganti and Kalathil, Dileep
author:
- given: Kishan Panaganti
  family: Badrinath
- given: Dileep
  family: Kalathil
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/badrinath21a/badrinath21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/badrinath21a/badrinath21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
