---
title: 'Non-Exponentially Weighted Aggregation: Regret Bounds for Unbounded Loss Functions'
abstract: 'We tackle the problem of online optimization with a general, possibly unbounded,
  loss function. It is well known that when the loss is bounded, the exponentially
  weighted aggregation strategy (EWA) leads to a regret in $\sqrt{T}$ after $T$ steps.
  In this paper, we study a generalized aggregation strategy, where the weights no
  longer depend exponentially on the losses. Our strategy is based on Follow The Regularized
  Leader (FTRL): we minimize the expected losses plus a regularizer, that is here
  a $\phi$-divergence. When the regularizer is the Kullback-Leibler divergence, we
  obtain EWA as a special case. Using alternative divergences enables unbounded losses,
  at the cost of a worst regret bound in some cases.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alquier21a
month: 0
tex_title: 'Non-Exponentially Weighted Aggregation: Regret Bounds for Unbounded Loss
  Functions'
firstpage: 207
lastpage: 218
page: 207-218
order: 207
cycles: false
bibtex_author: Alquier, Pierre
author:
- given: Pierre
  family: Alquier
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/alquier21a/alquier21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/alquier21a/alquier21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
