---
title: Locally Private k-Means in One Round
abstract: We provide an approximation algorithm for k-means clustering in the \emph{one-round}
  (aka \emph{non-interactive}) local model of differential privacy (DP). Our algorithm
  achieves an approximation ratio arbitrarily close to the best \emph{non private}
  approximation algorithm, improving upon previously known algorithms that only guarantee
  large (constant) approximation ratios. Furthermore, ours is the first constant-factor
  approximation algorithm for k-means that requires only \emph{one} round of communication
  in the local DP model, positively resolving an open question of Stemmer (SODA 2020).
  Our algorithmic framework is quite flexible; we demonstrate this by showing that
  it also yields a similar near-optimal approximation algorithm in the (one-round)
  shuffle DP model.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chang21a
month: 0
tex_title: Locally Private k-Means in One Round
firstpage: 1441
lastpage: 1451
page: 1441-1451
order: 1441
cycles: false
bibtex_author: Chang, Alisa and Ghazi, Badih and Kumar, Ravi and Manurangsi, Pasin
author:
- given: Alisa
  family: Chang
- given: Badih
  family: Ghazi
- given: Ravi
  family: Kumar
- given: Pasin
  family: Manurangsi
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/chang21a/chang21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/chang21a/chang21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
