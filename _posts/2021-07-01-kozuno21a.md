---
title: Revisiting Peng’s Q($λ$) for Modern Reinforcement Learning
abstract: 'Off-policy multi-step reinforcement learning algorithms consist of conservative
  and non-conservative algorithms: the former actively cut traces, whereas the latter
  do not. Recently, Munos et al. (2016) proved the convergence of conservative algorithms
  to an optimal Q-function. In contrast, non-conservative algorithms are thought to
  be unsafe and have a limited or no theoretical guarantee. Nonetheless, recent studies
  have shown that non-conservative algorithms empirically outperform conservative
  ones. Motivated by the empirical results and the lack of theory, we carry out theoretical
  analyses of Peng’s Q($\lambda$), a representative example of non-conservative algorithms.
  We prove that \emph{it also converges to an optimal policy} provided that the behavior
  policy slowly tracks a greedy policy in a way similar to conservative policy iteration.
  Such a result has been conjectured to be true but has not been proven. We also experiment
  with Peng’s Q($\lambda$) in complex continuous control tasks, confirming that Peng’s
  Q($\lambda$) often outperforms conservative algorithms despite its simplicity. These
  results indicate that Peng’s Q($\lambda$), which was thought to be unsafe, is a
  theoretically-sound and practically effective algorithm.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kozuno21a
month: 0
tex_title: Revisiting Peng’s Q($λ$) for Modern Reinforcement Learning
firstpage: 5794
lastpage: 5804
page: 5794-5804
order: 5794
cycles: false
bibtex_author: Kozuno, Tadashi and Tang, Yunhao and Rowland, Mark and Munos, Remi
  and Kapturowski, Steven and Dabney, Will and Valko, Michal and Abel, David
author:
- given: Tadashi
  family: Kozuno
- given: Yunhao
  family: Tang
- given: Mark
  family: Rowland
- given: Remi
  family: Munos
- given: Steven
  family: Kapturowski
- given: Will
  family: Dabney
- given: Michal
  family: Valko
- given: David
  family: Abel
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/kozuno21a/kozuno21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/kozuno21a/kozuno21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
