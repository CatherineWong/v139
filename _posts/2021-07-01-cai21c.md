---
title: Lenient Regret and Good-Action Identification in Gaussian Process Bandits
abstract: In this paper, we study the problem of Gaussian process (GP) bandits under
  relaxed optimization criteria stating that any function value above a certain threshold
  is “good enough”. On the theoretical side, we study various {\em lenient regret}
  notions in which all near-optimal actions incur zero penalty, and provide upper
  bounds on the lenient regret for GP-UCB and an elimination algorithm, circumventing
  the usual $O(\sqrt{T})$ term (with time horizon $T$) resulting from zooming extremely
  close towards the function maximum. In addition, we complement these upper bounds
  with algorithm-independent lower bounds. On the practical side, we consider the
  problem of finding a single “good action” according to a known pre-specified threshold,
  and introduce several good-action identification algorithms that exploit knowledge
  of the threshold. We experimentally find that such algorithms can typically find
  a good action faster than standard optimization-based approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cai21c
month: 0
tex_title: Lenient Regret and Good-Action Identification in Gaussian Process Bandits
firstpage: 1183
lastpage: 1192
page: 1183-1192
order: 1183
cycles: false
bibtex_author: Cai, Xu and Gomes, Selwyn and Scarlett, Jonathan
author:
- given: Xu
  family: Cai
- given: Selwyn
  family: Gomes
- given: Jonathan
  family: Scarlett
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/cai21c/cai21c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/cai21c/cai21c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
