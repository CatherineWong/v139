---
title: Adversarial Policy Learning in Two-player Competitive Games
abstract: In a two-player deep reinforcement learning task, recent work shows an attacker
  could learn an adversarial policy that triggers a target agent to perform poorly
  and even react in an undesired way. However, its efficacy heavily relies upon the
  zero-sum assumption made in the two-player game. In this work, we propose a new
  adversarial learning algorithm. It addresses the problem by resetting the optimization
  goal in the learning process and designing a new surrogate optimization function.
  Our experiments show that our method significantly improves adversarial agents’
  exploitability compared with the state-of-art attack. Besides, we also discover
  that our method could augment an agent with the ability to abuse the target game’s
  unfairness. Finally, we show that agents adversarially re-trained against our adversarial
  agents could obtain stronger adversary-resistance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo21b
month: 0
tex_title: Adversarial Policy Learning in Two-player Competitive Games
firstpage: 3910
lastpage: 3919
page: 3910-3919
order: 3910
cycles: false
bibtex_author: Guo, Wenbo and Wu, Xian and Huang, Sui and Xing, Xinyu
author:
- given: Wenbo
  family: Guo
- given: Xian
  family: Wu
- given: Sui
  family: Huang
- given: Xinyu
  family: Xing
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/guo21b/guo21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/guo21b/guo21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
