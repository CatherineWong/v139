---
title: Multiplying Matrices Without Multiplying
abstract: Multiplying matrices is among the most fundamental and most computationally
  demanding operations in machine learning and scientific computing. Consequently,
  the task of efficiently approximating matrix products has received significant attention.
  We introduce a learning-based algorithm for this task that greatly outperforms existing
  methods. Experiments using hundreds of matrices from diverse domains show that it
  often runs 10x faster than alternatives at a given level of error, as well as 100x
  faster than exact matrix multiplication. In the common case that one matrix is known
  ahead of time, our method also has the interesting property that it requires zero
  multiply-adds. These results suggest that a mixture of hashing, averaging, and byte
  shuffling{—}the core operations of our method{—}could be a more promising building
  block for machine learning than the sparsified, factorized, and/or scalar quantized
  matrix products that have recently been the focus of substantial research and hardware
  investment.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: blalock21a
month: 0
tex_title: Multiplying Matrices Without Multiplying
firstpage: 992
lastpage: 1004
page: 992-1004
order: 992
cycles: false
bibtex_author: Blalock, Davis and Guttag, John
author:
- given: Davis
  family: Blalock
- given: John
  family: Guttag
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/blalock21a/blalock21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/blalock21a/blalock21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
