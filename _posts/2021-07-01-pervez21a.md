---
title: Spectral Smoothing Unveils Phase Transitions in Hierarchical Variational Autoencoders
abstract: Variational autoencoders with deep hierarchies of stochastic layers have
  been known to suffer from the problem of posterior collapse, where the top layers
  fall back to the prior and become independent of input. We suggest that the hierarchical
  VAE objective explicitly includes the variance of the function parameterizing the
  mean and variance of the latent Gaussian distribution which itself is often a high
  variance function. Building on this we generalize VAE neural networks by incorporating
  a smoothing parameter motivated by Gaussian analysis to reduce higher frequency
  components and consequently the variance in parameterizing functions and show that
  this can help to solve the problem of posterior collapse. We further show that under
  such smoothing the VAE loss exhibits a phase transition, where the top layer KL
  divergence sharply drops to zero at a critical value of the smoothing parameter
  that is similar for the same model across datasets. We validate the phenomenon across
  model configurations and datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pervez21a
month: 0
tex_title: Spectral Smoothing Unveils Phase Transitions in Hierarchical Variational
  Autoencoders
firstpage: 8536
lastpage: 8545
page: 8536-8545
order: 8536
cycles: false
bibtex_author: Pervez, Adeel and Gavves, Efstratios
author:
- given: Adeel
  family: Pervez
- given: Efstratios
  family: Gavves
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/pervez21a/pervez21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/pervez21a/pervez21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
