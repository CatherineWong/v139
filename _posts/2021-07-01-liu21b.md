---
title: 'APS: Active Pretraining with Successor Features'
abstract: We introduce a new unsupervised pretraining objective for reinforcement
  learning. During the unsupervised reward-free pretraining phase, the agent maximizes
  mutual information between tasks and states induced by the policy. Our key contribution
  is a novel lower bound of this intractable quantity. We show that by reinterpreting
  and combining variational successor features \citep{Hansen2020Fast} with nonparametric
  entropy maximization \citep{liu2021behavior}, the intractable mutual information
  can be efficiently optimized. The proposed method Active Pretraining with Successor
  Feature (APS) explores the environment via nonparametric entropy maximization, and
  the explored data can be efficiently leveraged to learn behavior by variational
  successor features. APS addresses the limitations of existing mutual information
  maximization based and entropy maximization based unsupervised RL, and combines
  the best of both worlds. When evaluated on the Atari 100k data-efficiency benchmark,
  our approach significantly outperforms previous methods combining unsupervised pretraining
  with task-specific finetuning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu21b
month: 0
tex_title: 'APS: Active Pretraining with Successor Features'
firstpage: 6736
lastpage: 6747
page: 6736-6747
order: 6736
cycles: false
bibtex_author: Liu, Hao and Abbeel, Pieter
author:
- given: Hao
  family: Liu
- given: Pieter
  family: Abbeel
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/liu21b/liu21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/liu21b/liu21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
