---
title: 'Soft then Hard: Rethinking the Quantization in Neural Image Compression'
abstract: 'Quantization is one of the core components in lossy image compression.
  For neural image compression, end-to-end optimization requires differentiable approximations
  of quantization, which can generally be grouped into three categories: additive
  uniform noise, straight-through estimator and soft-to-hard annealing. Training with
  additive uniform noise approximates the quantization error variationally but suffers
  from the train-test mismatch. The other two methods do not encounter this mismatch
  but, as shown in this paper, hurt the rate-distortion performance since the latent
  representation ability is weakened. We thus propose a novel soft-then-hard quantization
  strategy for neural image compression that first learns an expressive latent space
  softly, then closes the train-test mismatch with hard quantization. In addition,
  beyond the fixed integer-quantization, we apply scaled additive uniform noise to
  adaptively control the quantization granularity by deriving a new variational upper
  bound on actual rate. Experiments demonstrate that our proposed methods are easy
  to adopt, stable to train, and highly effective especially on complex compression
  models.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo21c
month: 0
tex_title: 'Soft then Hard: Rethinking the Quantization in Neural Image Compression'
firstpage: 3920
lastpage: 3929
page: 3920-3929
order: 3920
cycles: false
bibtex_author: Guo, Zongyu and Zhang, Zhizheng and Feng, Runsen and Chen, Zhibo
author:
- given: Zongyu
  family: Guo
- given: Zhizheng
  family: Zhang
- given: Runsen
  family: Feng
- given: Zhibo
  family: Chen
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/guo21c/guo21c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/guo21c/guo21c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
