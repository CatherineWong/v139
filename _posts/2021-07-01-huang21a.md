---
title: On Recovering from Modeling Errors Using Testing Bayesian Networks
abstract: We consider the problem of supervised learning with Bayesian Networks when
  the used dependency structure is incomplete due to missing edges or missing variable
  states. These modeling errors induce independence constraints on the learned model
  that may not hold in the true, data-generating distribution. We provide a unified
  treatment of these modeling errors as instances of state-space abstractions. We
  then identify a class of Bayesian Networks and queries which allow one to fully
  recover from such modeling errors if one can choose Conditional Probability Tables
  (CPTs) dynamically based on evidence. We show theoretically that the recently proposed
  Testing Bayesian Networks (TBNs), which can be trained by compiling them into Testing
  Arithmetic Circuits (TACs), provide a promising construct for emulating this CPT
  selection mechanism. Finally, we present empirical results that illustrate the promise
  of TBNs as a tool for recovering from certain modeling errors in the context of
  supervised learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang21a
month: 0
tex_title: On Recovering from Modeling Errors Using Testing Bayesian Networks
firstpage: 4402
lastpage: 4411
page: 4402-4411
order: 4402
cycles: false
bibtex_author: Huang, Haiying and Darwiche, Adnan
author:
- given: Haiying
  family: Huang
- given: Adnan
  family: Darwiche
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/huang21a/huang21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/huang21a/huang21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
