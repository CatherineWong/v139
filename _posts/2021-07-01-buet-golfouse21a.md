---
title: 'Narrow Margins: Classification, Margins and Fat Tails'
abstract: It is well-known that, for separable data, the regularised two-class logistic
  regression or support vector machine re-normalised estimate converges to the maximal
  margin classifier as the regularisation hyper-parameter $\lambda$ goes to 0. The
  fact that different loss functions may lead to the same solution is of theoretical
  and practical relevance as margin maximisation allows more straightforward considerations
  in terms of generalisation and geometric interpretation. We investigate the case
  where this convergence property is not guaranteed to hold and show that it can be
  fully characterised by the distribution of error terms in the latent variable interpretation
  of linear classifiers. In particular, if errors follow a regularly varying distribution,
  then the regularised and re-normalised estimate does not converge to the maximal
  margin classifier. This shows that classification with fat tails has a qualitatively
  different behaviour, which should be taken into account when considering real-life
  data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: buet-golfouse21a
month: 0
tex_title: 'Narrow Margins: Classification, Margins and Fat Tails'
firstpage: 1127
lastpage: 1135
page: 1127-1135
order: 1127
cycles: false
bibtex_author: Buet-Golfouse, Francois
author:
- given: Francois
  family: Buet-Golfouse
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/buet-golfouse21a/buet-golfouse21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
