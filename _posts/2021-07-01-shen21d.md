---
title: State Relevance for Off-Policy Evaluation
abstract: Importance sampling-based estimators for off-policy evaluation (OPE) are
  valued for their simplicity, unbiasedness, and reliance on relatively few assumptions.
  However, the variance of these estimators is often high, especially when trajectories
  are of different lengths. In this work, we introduce Omitting-States-Irrelevant-to-Return
  Importance Sampling (OSIRIS), an estimator which reduces variance by strategically
  omitting likelihood ratios associated with certain states. We formalize the conditions
  under which OSIRIS is unbiased and has lower variance than ordinary importance sampling,
  and we demonstrate these properties empirically.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen21d
month: 0
tex_title: State Relevance for Off-Policy Evaluation
firstpage: 9537
lastpage: 9546
page: 9537-9546
order: 9537
cycles: false
bibtex_author: Shen, Simon P and Ma, Yecheng and Gottesman, Omer and Doshi-Velez,
  Finale
author:
- given: Simon P
  family: Shen
- given: Yecheng
  family: Ma
- given: Omer
  family: Gottesman
- given: Finale
  family: Doshi-Velez
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/shen21d/shen21d.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/shen21d/shen21d-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
