---
title: 'Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training'
abstract: Self-training is a standard approach to semi-supervised learning where the
  learnerâ€™s own predictions on unlabeled data are used as supervision during training.
  In this paper, we reinterpret this label assignment process as an optimal transportation
  problem between examples and classes, wherein the cost of assigning an example to
  a class is mediated by the current predictions of the classifier. This formulation
  facilitates a practical annealing strategy for label assignment and allows for the
  inclusion of prior knowledge on class proportions via flexible upper bound constraints.
  The solutions to these assignment problems can be efficiently approximated using
  Sinkhorn iteration, thus enabling their use in the inner loop of standard stochastic
  optimization algorithms. We demonstrate the effectiveness of our algorithm on the
  CIFAR-10, CIFAR-100, and SVHN datasets in comparison with FixMatch, a state-of-the-art
  self-training algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tai21a
month: 0
tex_title: 'Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed
  Self-Training'
firstpage: 10065
lastpage: 10075
page: 10065-10075
order: 10065
cycles: false
bibtex_author: Tai, Kai Sheng and Bailis, Peter D and Valiant, Gregory
author:
- given: Kai Sheng
  family: Tai
- given: Peter D
  family: Bailis
- given: Gregory
  family: Valiant
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/tai21a/tai21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/tai21a/tai21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
