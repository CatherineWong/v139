---
title: Robust Learning for Data Poisoning Attacks
abstract: We investigate the robustness of stochastic approximation approaches against
  data poisoning attacks. We focus on two-layer neural networks with ReLU activation
  and show that under a specific notion of separability in the RKHS induced by the
  infinite-width network, training (finite-width) networks with stochastic gradient
  descent is robust against data poisoning attacks. Interestingly, we find that in
  addition to a lower bound on the width of the network, which is standard in the
  literature, we also require a distribution-dependent upper bound on the width for
  robust generalization. We provide extensive empirical evaluations that support and
  validate our theoretical results.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21r
month: 0
tex_title: Robust Learning for Data Poisoning Attacks
firstpage: 10859
lastpage: 10869
page: 10859-10869
order: 10859
cycles: false
bibtex_author: Wang, Yunjuan and Mianjy, Poorya and Arora, Raman
author:
- given: Yunjuan
  family: Wang
- given: Poorya
  family: Mianjy
- given: Raman
  family: Arora
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/wang21r/wang21r.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/wang21r/wang21r-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
