---
title: 'Efficient Statistical Tests: A Neural Tangent Kernel Approach'
abstract: For machine learning models to make reliable predictions in deployment,
  one needs to ensure the previously unknown test samples need to be sufficiently
  similar to the training data. The commonly used shift-invariant kernels do not have
  the compositionality and fail to capture invariances in high-dimensional data in
  computer vision. We propose a shift-invariant convolutional neural tangent kernel
  (SCNTK) based outlier detector and two-sample tests with maximum mean discrepancy
  (MMD) that is O(n) in the number of samples due to using the random feature approximation.
  On MNIST and CIFAR10 with various types of dataset shifts, we empirically show that
  statistical tests with such compositional kernels, inherited from infinitely wide
  neural networks, achieve higher detection accuracy than existing non-parametric
  methods. Our method also provides a competitive alternative to adapted kernel methods
  that require a training phase.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jia21a
month: 0
tex_title: 'Efficient Statistical Tests: A Neural Tangent Kernel Approach'
firstpage: 4893
lastpage: 4903
page: 4893-4903
order: 4893
cycles: false
bibtex_author: Jia, Sheng and Nezhadarya, Ehsan and Wu, Yuhuai and Ba, Jimmy
author:
- given: Sheng
  family: Jia
- given: Ehsan
  family: Nezhadarya
- given: Yuhuai
  family: Wu
- given: Jimmy
  family: Ba
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/jia21a/jia21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/jia21a/jia21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
