---
title: An Identifiable Double VAE For Disentangled Representations
abstract: A large part of the literature on learning disentangled representations
  focuses on variational autoencoders (VAEs). Recent developments demonstrate that
  disentanglement cannot be obtained in a fully unsupervised setting without inductive
  biases on models and data. However, Khemakhem et al., AISTATS, 2020 suggest that
  employing a particular form of factorized prior, conditionally dependent on auxiliary
  variables complementing input observations, can be one such bias, resulting in an
  identifiable model with guarantees on disentanglement. Working along this line,
  we propose a novel VAE-based generative model with theoretical guarantees on identifiability.
  We obtain our conditional prior over the latents by learning an optimal representation,
  which imposes an additional strength on their regularization. We also extend our
  method to semi-supervised settings. Experimental results indicate superior performance
  with respect to state-of-the-art approaches, according to several established metrics
  proposed in the literature on disentanglement.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mita21a
month: 0
tex_title: An Identifiable Double VAE For Disentangled Representations
firstpage: 7769
lastpage: 7779
page: 7769-7779
order: 7769
cycles: false
bibtex_author: Mita, Graziano and Filippone, Maurizio and Michiardi, Pietro
author:
- given: Graziano
  family: Mita
- given: Maurizio
  family: Filippone
- given: Pietro
  family: Michiardi
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/mita21a/mita21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/mita21a/mita21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
