---
title: 'Align, then memorise: the dynamics of learning with feedback alignment'
abstract: 'Direct Feedback Alignment (DFA) is emerging as an efficient and biologically
  plausible alternative to backpropagation for training deep neural networks. Despite
  relying on random feedback weights for the backward pass, DFA successfully trains
  state-of-the-art models such as Transformers. On the other hand, it notoriously
  fails to train convolutional networks. An understanding of the inner workings of
  DFA to explain these diverging results remains elusive. Here, we propose a theory
  of feedback alignment algorithms. We first show that learning in shallow networks
  proceeds in two steps: an alignment phase, where the model adapts its weights to
  align the approximate gradient with the true gradient of the loss function, is followed
  by a memorisation phase, where the model focuses on fitting the data. This two-step
  process has a degeneracy breaking effect: out of all the low-loss solutions in the
  landscape, a net-work trained with DFA naturally converges to the solution which
  maximises gradient alignment. We also identify a key quantity underlying alignment
  in deep linear networks: the conditioning of the alignment matrices. The latter
  enables a detailed understanding of the impact of data structure on alignment, and
  suggests a simple explanation for the well-known failure of DFA to train convolutional
  neural networks. Numerical experiments on MNIST and CIFAR10 clearly demonstrate
  degeneracy breaking in deep non-linear networks and show that the align-then-memorize
  process occurs sequentially from the bottom layers of the network to the top.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: refinetti21a
month: 0
tex_title: 'Align, then memorise: the dynamics of learning with feedback alignment'
firstpage: 8925
lastpage: 8935
page: 8925-8935
order: 8925
cycles: false
bibtex_author: Refinetti, Maria and D'Ascoli, St{\'e}phane and Ohana, Ruben and Goldt,
  Sebastian
author:
- given: Maria
  family: Refinetti
- given: Stéphane
  family: D’Ascoli
- given: Ruben
  family: Ohana
- given: Sebastian
  family: Goldt
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/refinetti21a/refinetti21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v139/refinetti21a/refinetti21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
