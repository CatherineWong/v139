---
title: Boosting for Online Convex Optimization
abstract: We consider the decision-making framework of online convex optimization
  with a very large number of experts. This setting is ubiquitous in contextual and
  reinforcement learning problems, where the size of the policy class renders enumeration
  and search within the policy class infeasible. Instead, we consider generalizing
  the methodology of online boosting. We define a weak learning algorithm as a mechanism
  that guarantees multiplicatively approximate regret against a base class of experts.
  In this access model, we give an efficient boosting algorithm that guarantees near-optimal
  regret against the convex hull of the base class. We consider both full and partial
  (a.k.a. bandit) information feedback models. We also give an analogous efficient
  boosting algorithm for the i.i.d. statistical setting. Our results simultaneously
  generalize online boosting and gradient boosting guarantees to contextual learning
  model, online convex optimization and bandit linear optimization settings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hazan21a
month: 0
tex_title: Boosting for Online Convex Optimization
firstpage: 4140
lastpage: 4149
page: 4140-4149
order: 4140
cycles: false
bibtex_author: Hazan, Elad and Singh, Karan
author:
- given: Elad
  family: Hazan
- given: Karan
  family: Singh
date: 2021-07-01
address:
container-title: Proceedings of the 38th International Conference on Machine Learning
volume: '139'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 1
pdf: http://proceedings.mlr.press/v139/hazan21a/hazan21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
